{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmrithavarshiniR/OpenAITraining/blob/main/Hackathon/Generate_testcase.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lNuPs5MmZN_"
      },
      "source": [
        "## Creating an Empty File\n",
        "\n",
        "We will also create an empty text file named `app.txt`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXLVxYfAmZOA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "191cc4a1-9af3-4e88-cecc-ae7b7ef2ce6c"
      },
      "source": [
        "# Creating an empty text file named app.txt\n",
        "file_name = 'app.txt'\n",
        "\n",
        "with open(file_name, 'w') as file:\n",
        "    pass\n",
        "\n",
        "print(f\"Created file: {file_name}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created file: app.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K-Mx8ukmZON"
      },
      "source": [
        "## Interacting with Azure OpenAI Service\n",
        "\n",
        "Finally, we will look at how to interact with the Azure OpenAI service to perform various tasks related to our code."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==1.13.3"
      ],
      "metadata": {
        "id": "rhzA2QmInOpt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efa5bce9-8564-4034-eaff-540fdf055d78"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==1.13.3\n",
            "  Downloading openai-1.13.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.13.3) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai==1.13.3)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.13.3) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.13.3) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.13.3) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.13.3)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.13.3)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.13.3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.13.3) (2.20.1)\n",
            "Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 openai-1.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from openai import AsyncAzureOpenAI"
      ],
      "metadata": {
        "id": "2nQMKZ8znVLW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmPGJhzpmZOP"
      },
      "source": [
        "\n",
        "\n",
        "# Set to True to print the full response from OpenAI for each call\n",
        "printFullResponse = False\n",
        "\n",
        "async def main():\n",
        "  try:\n",
        "        # Get configuration settings\n",
        "        # Configuration settings\n",
        "        azure_oai_endpoint = \"https://eygroup3.openai.azure.com/\"\n",
        "        azure_oai_key = \"4b298d12925d41dcafb334fbf625b229\"\n",
        "        azure_oai_deployment = \"Hackathon-group3\"\n",
        "\n",
        "        # Configure the Azure OpenAI client\n",
        "        client = AsyncAzureOpenAI(\n",
        "            azure_endpoint = azure_oai_endpoint,\n",
        "            api_key=azure_oai_key,\n",
        "            api_version=\"2024-02-15-preview\"\n",
        "        )\n",
        "\n",
        "        while True:\n",
        "            print('\\n1: Add comments to my function\\n' +\n",
        "                  '2: Write testcases for my function\\n' +\n",
        "                  '\"quit\" to exit the program\\n')\n",
        "            command = input('Enter a number to select a task:')\n",
        "\n",
        "            if command.lower() == 'quit':\n",
        "                print('Exiting program...')\n",
        "                break\n",
        "\n",
        "            user_input = input('\\nEnter a prompt: ')\n",
        "            if command == '1' or command == '2':\n",
        "                file = open(file=\"Code.py\", encoding=\"utf8\").read()\n",
        "            else :\n",
        "                print(\"Invalid input. Please try again.\")\n",
        "                continue\n",
        "\n",
        "            prompt = user_input + file\n",
        "            await call_openai_model(prompt, model=azure_oai_deployment, client=client)\n",
        "\n",
        "  except Exception as ex:\n",
        "        print(ex)\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def call_openai_model(prompt, model, client):\n",
        "    # Provide a basic user message, and use the prompt content as the user message\n",
        "    system_message = \"You are a helpful AI assistant that helps in creating the testcases for the py file.\"\n",
        "    user_message = prompt\n",
        "\n",
        "    # Format and send the request to the model\n",
        "    messages =[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message},\n",
        "    ]\n",
        "\n",
        "    # Call the Azure OpenAI model\n",
        "    response = await client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.7,\n",
        "        max_tokens=1000\n",
        "    )\n",
        "\n",
        "    # Print the response to the console, if desired\n",
        "    if printFullResponse:\n",
        "        print(response)\n",
        "\n",
        "    # Write the response to a file\n",
        "    results_file = open(file=\"app.txt\", mode=\"w\", encoding=\"utf8\")\n",
        "    results_file.write(response.choices[0].message.content)\n",
        "    print(\"\\nResponse written to result/app.txt\\n\\n\")\n"
      ],
      "metadata": {
        "id": "t-DWkZ0ImvrZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the main function in the event loop\n",
        "await main()"
      ],
      "metadata": {
        "id": "tDoRyK1Am3In",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed940b67-3557-4f47-8a18-e1e8578892c1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1: Add comments to my function\n",
            "2: Write testcases for my function\n",
            "\"quit\" to exit the program\n",
            "\n",
            "Enter a number to select a task:1\n",
            "\n",
            "Enter a prompt: function is for\n",
            "\n",
            "Response written to result/app.txt\n",
            "\n",
            "\n",
            "\n",
            "1: Add comments to my function\n",
            "2: Write testcases for my function\n",
            "\"quit\" to exit the program\n",
            "\n",
            "Enter a number to select a task:2\n",
            "\n",
            "Enter a prompt: testcases\n",
            "\n",
            "Response written to result/app.txt\n",
            "\n",
            "\n",
            "\n",
            "1: Add comments to my function\n",
            "2: Write testcases for my function\n",
            "\"quit\" to exit the program\n",
            "\n",
            "Enter a number to select a task:q\n",
            "\n",
            "Enter a prompt: quit\n",
            "Invalid input. Please try again.\n",
            "\n",
            "1: Add comments to my function\n",
            "2: Write testcases for my function\n",
            "\"quit\" to exit the program\n",
            "\n",
            "Enter a number to select a task:quit\n",
            "Exiting program...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vJGBuL6Rrds9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}